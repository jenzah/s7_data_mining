{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP - Prétraitement des données - Achats alimentaires\n",
    "\n",
    "**Objectif**: Nettoyer et préparer le jeu de données bruité `donnees_brutes_achats.xlsx` pour le rendre exploitable.\n",
    "\n",
    "**Étapes**:\n",
    "1. Importer les données\n",
    "2. Diagnostiquer la qualité des données\n",
    "3. Gérer les doublons\n",
    "4. Uniformiser les chaînes de caractères\n",
    "5. Harmoniser les catégories\n",
    "6. Unifier le format des dates\n",
    "7. Gérer les valeurs manquantes\n",
    "8. Détecter et traiter les valeurs aberrantes\n",
    "9. Supprimer la colonne 'Notes'\n",
    "10. Exporter la table finale propre\n",
    "\n",
    "\n",
    "# **Rapport de nettoyage**\n",
    "\n",
    "### Problèmes détectés:\n",
    "1. **Doublons**: Présence de lignes dupliquées (exactes et par TransactionID)\n",
    "2. **Chaînes non uniformisées**: Espaces parasites, casse incohérente, synonymes\n",
    "3. **Catégories incohérentes**: Variations orthographiques et formats différents\n",
    "4. **Dates hétérogènes**: Formats de dates variés\n",
    "5. **Valeurs manquantes**: Dans les colonnes Quantité et Prix\n",
    "6. **Valeurs aberrantes**: Quantités négatives/excessives, prix à 999\n",
    "7. **Produits invalides**: Lignes avec '—' ou vides\n",
    "\n",
    "### Choix de nettoyage:\n",
    "- **Doublons**: Suppression des doublons exacts puis par TransactionID (conservation de la première occurrence)\n",
    "- **Uniformisation**: Trim des espaces, conversion en minuscules, normalisation des accents\n",
    "- **Synonymes**: Mapping manuel des variantes (pates→pâtes, tomato→tomate, etc.)\n",
    "- **Catégories**: Harmonisation via mapping (epicerie→épicerie, fruits-legumes→fruits & légumes)\n",
    "- **Dates**: Conversion avec `pd.to_datetime(dayfirst=True)` au format YYYY-MM-DD\n",
    "- **Valeurs manquantes**: Imputation par la **médiane** (plus robuste que la moyenne face aux outliers)\n",
    "- **Aberrants**: \n",
    "  - Quantités < 0 ou > 100: remplacement par la médiane\n",
    "  - Prix > 100: remplacement par la médiane\n",
    "  - Produits invalides: suppression des lignes\n",
    "- **Colonne Notes**: Supprimée (non utilisée pour l'analyse)\n",
    "\n",
    "### Impact:\n",
    "Les statistiques détaillées (nombre de lignes supprimées, valeurs modifiées) sont affichées dans les cellules ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Nettoyage des données**\n",
    "## 1. Import des bibliothèques et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes: 51\n",
      "\n",
      "Premières lignes du dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Produit</th>\n",
       "      <th>Quantité</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>Date</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>Boulangerie</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lait</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Laitage</td>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Beurre</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>Laitage</td>\n",
       "      <td>2025/09/01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tomate</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>Fruits &amp; Légumes</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>tomato</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>fruits et legumes</td>\n",
       "      <td>02-09-2025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pâtes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Épicerie</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>promo? 2 pour 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>pates</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>epicerie</td>\n",
       "      <td>02/09/25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Riz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>Épicerie</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Riz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>épicerie</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Yaourt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Laitage</td>\n",
       "      <td>2025-09-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID Produit  Quantité  Prix          Catégorie        Date  \\\n",
       "0              1    Pain       1.0  1.20        Boulangerie  2025-09-01   \n",
       "1              2    Lait       2.0  0.95            Laitage  01/09/2025   \n",
       "2              3  Beurre       1.0  2.80            Laitage  2025/09/01   \n",
       "3              4  Tomate       3.0  1.99   Fruits & Légumes  2025-09-02   \n",
       "4              5  tomato       2.0  2.10  fruits et legumes  02-09-2025   \n",
       "5              6   Pâtes       1.0  0.89           Épicerie  2025-09-02   \n",
       "6              7   pates       2.0  0.89           epicerie    02/09/25   \n",
       "7              8     Riz       1.0  1.10           Épicerie  2025-09-03   \n",
       "8              9    Riz        5.0  1.10           épicerie  2025-09-03   \n",
       "9             10  Yaourt       6.0  0.45            Laitage  2025-09-03   \n",
       "\n",
       "             Notes  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "5  promo? 2 pour 1  \n",
       "6              NaN  \n",
       "7              NaN  \n",
       "8              NaN  \n",
       "9              NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data\n",
    "df = pd.read_excel('donnees_brutes_achats.xlsx')\n",
    "\n",
    "# Preview of dataset\n",
    "print(f\"Nombre total de lignes: {len(df)}\")\n",
    "print(\"\\nPremières lignes du dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diagnostic de la qualité des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Informations sur le dataset ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   TransactionID  51 non-null     int64  \n",
      " 1   Produit        51 non-null     object \n",
      " 2   Quantité       49 non-null     float64\n",
      " 3   Prix           49 non-null     float64\n",
      " 4   Catégorie      49 non-null     object \n",
      " 5   Date           51 non-null     object \n",
      " 6   Notes          4 non-null      object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# General information\n",
    "print(\"=== Informations sur le dataset ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Description statistique ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Produit</th>\n",
       "      <th>Quantité</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>Date</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Beurre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Laitage</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>promo? 2 pour 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.803922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.061224</td>\n",
       "      <td>22.349184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.593176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.494943</td>\n",
       "      <td>142.437880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID Produit     Quantité        Prix Catégorie        Date  \\\n",
       "count       51.000000      51    49.000000   49.000000        49          51   \n",
       "unique            NaN      40          NaN         NaN        22          29   \n",
       "top               NaN  Beurre          NaN         NaN   Laitage  2025-09-06   \n",
       "freq              NaN       4          NaN         NaN         9           4   \n",
       "mean        25.803922     NaN    23.061224   22.349184       NaN         NaN   \n",
       "std         14.593176     NaN   142.494943  142.437880       NaN         NaN   \n",
       "min          1.000000     NaN    -1.000000    0.000000       NaN         NaN   \n",
       "25%         13.500000     NaN     1.000000    0.900000       NaN         NaN   \n",
       "50%         26.000000     NaN     2.000000    1.750000       NaN         NaN   \n",
       "75%         38.500000     NaN     4.000000    2.800000       NaN         NaN   \n",
       "max         50.000000     NaN  1000.000000  999.000000       NaN         NaN   \n",
       "\n",
       "                  Notes  \n",
       "count                 4  \n",
       "unique                4  \n",
       "top     promo? 2 pour 1  \n",
       "freq                  1  \n",
       "mean                NaN  \n",
       "std                 NaN  \n",
       "min                 NaN  \n",
       "25%                 NaN  \n",
       "50%                 NaN  \n",
       "75%                 NaN  \n",
       "max                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical description\n",
    "print(\"\\n=== Description statistique ===\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Valeurs manquantes ===\n",
      "           Nombre de valeurs manquantes  Pourcentage\n",
      "Quantité                              2     3.921569\n",
      "Prix                                  2     3.921569\n",
      "Catégorie                             2     3.921569\n",
      "Notes                                47    92.156863\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "print(\"\\n=== Valeurs manquantes ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Nombre de valeurs manquantes': missing_values,\n",
    "    'Pourcentage': missing_percent\n",
    "})\n",
    "print(missing_df[missing_df['Nombre de valeurs manquantes'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyse des doublons ===\n",
      "Nombre de doublons exacts: 1\n",
      "Nombre de doublons par TransactionID: 1\n"
     ]
    }
   ],
   "source": [
    "# Duplicates\n",
    "print(\"\\n=== Analyse des doublons ===\")\n",
    "nb_duplicates = df.duplicated().sum()\n",
    "print(f\"Nombre de doublons exacts: {nb_duplicates}\")\n",
    "\n",
    "# TransactionID duplicates\n",
    "nb_id_duplicates = df.duplicated(subset=['TransactionID']).sum()\n",
    "print(f\"Nombre de doublons par TransactionID: {nb_id_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Valeurs uniques ===\n",
      "TransactionID: 50 valeurs uniques\n",
      "Produit: 40 valeurs uniques\n",
      "  Exemples: ['Pain' 'Lait' 'Beurre' 'Tomate' 'tomato' 'Pâtes' 'pates' 'Riz' 'Riz '\n",
      " 'Yaourt']\n",
      "Quantité: 12 valeurs uniques\n",
      "Prix: 34 valeurs uniques\n",
      "Catégorie: 22 valeurs uniques\n",
      "  Exemples: ['Boulangerie' 'Laitage' 'Fruits & Légumes' 'fruits et legumes' 'Épicerie'\n",
      " 'epicerie' 'épicerie' 'laitage' 'Œufs & Ovoproduits' 'oeufs']\n",
      "Date: 29 valeurs uniques\n",
      "Notes: 4 valeurs uniques\n"
     ]
    }
   ],
   "source": [
    "# Unique values\n",
    "print(\"\\n=== Valeurs uniques ===\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} valeurs uniques\")\n",
    "    if col in ['Produit', 'Catégorie'] and df[col].nunique() < 50:\n",
    "        print(f\"  Exemples: {df[col].unique()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gestion des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avant suppression des doublons: 51\n",
      "\n",
      "Nombre de lignes après suppression des doublons exacts: 50\n",
      "Doublons exacts supprimés: 1\n",
      "\n",
      "Nombre de lignes après suppression des doublons par TransactionID: 50\n",
      "Doublons par TransactionID supprimés: 0\n"
     ]
    }
   ],
   "source": [
    "# Save original df lenght\n",
    "len_original = len(df)\n",
    "print(f\"Nombre de lignes avant suppression des doublons: {len_original}\\n\")\n",
    "\n",
    "# Delete duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Nombre de lignes après suppression des doublons exacts: {len(df)}\")\n",
    "print(f\"Doublons exacts supprimés: {len_original - len(df)}\\n\")\n",
    "\n",
    "# Delete ID duplicates (keep first)\n",
    "len_before_id = len(df)\n",
    "df.drop_duplicates(subset=['TransactionID'], inplace=True)\n",
    "print(f\"Nombre de lignes après suppression des doublons par TransactionID: {len(df)}\")\n",
    "print(f\"Doublons par TransactionID supprimés: {len_before_id - len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uniformisation des chaînes de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Uniformisation des chaînes ===\n",
      "\n",
      "Exemples de produits avant nettoyage:\n",
      "['Pain', 'Lait', 'Beurre', 'Tomate', 'tomato', 'Pâtes', 'pates', 'Riz', 'Riz ', 'Yaourt', 'yaourts', 'Oeufs', 'oeuf', 'Poulet', 'Poisson', 'Banane', 'bananes', 'Pomme', 'Pommes', 'Concombre']\n"
     ]
    }
   ],
   "source": [
    "# Trim spaces, and convert into lower case\n",
    "print(\"=== Uniformisation des chaînes ===\")\n",
    "print(f\"\\nExemples de produits avant nettoyage:\")\n",
    "print(df['Produit'].head(20).tolist())\n",
    "\n",
    "# Clean Produit\n",
    "df['Produit'] = df['Produit'].astype(str).str.strip()\n",
    "\n",
    "#Clean Catégorie\n",
    "df['Catégorie'] = df['Catégorie'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise strings - remove accents\n",
    "df['Produit_normalise'] = (df['Produit']\n",
    "    .str.lower()\n",
    "    .str.replace('é', 'e', regex=False)\n",
    "    .str.replace('è', 'e', regex=False)\n",
    "    .str.replace('ê', 'e', regex=False)\n",
    "    .str.replace('à', 'a', regex=False)\n",
    "    .str.replace('â', 'a', regex=False)\n",
    "    .str.replace('î', 'i', regex=False)\n",
    "    .str.replace('ï', 'i', regex=False)\n",
    "    .str.replace('ô', 'o', regex=False)\n",
    "    .str.replace('ö', 'o', regex=False)\n",
    "    .str.replace('û', 'u', regex=False)\n",
    "    .str.replace('ü', 'u', regex=False)\n",
    "    .str.replace('ç', 'c', regex=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemples de produits après harmonisation:\n",
      "['pain', 'lait', 'beurre', 'tomate', 'tomate', 'pâtes', 'pâtes', 'riz', 'riz', 'yaourt', 'yaourt', 'oeufs', 'oeuf', 'poulet', 'poisson', 'banane', 'bananes', 'pomme', 'pommes', 'concombre']\n",
      "\n",
      "Produits uniques après harmonisation: 30\n"
     ]
    }
   ],
   "source": [
    "# Treat fuzzy duplicates\n",
    "mapping_products = {\n",
    "    'pates': 'pâtes',\n",
    "    'the': 'thé',\n",
    "    'cafe': 'café',\n",
    "    'tomato': 'tomate',\n",
    "    'yaourts': 'yaourt',\n",
    "    'riz ': 'riz',\n",
    "    'frommage': 'fromage',\n",
    "    'huile olive': \"huile d'olive\",\n",
    "    'corn flakes': 'corn-flakes',\n",
    "    'fromage': 'fromage',\n",
    "    'tomates': 'tomate'\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df['Produit'] = df['Produit_normalise'].replace(mapping_products)\n",
    "\n",
    "print(f\"\\nExemples de produits après harmonisation:\")\n",
    "print(df['Produit'].head(20).tolist())\n",
    "print(f\"\\nProduits uniques après harmonisation: {df['Produit'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Harmonisation des catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Harmonisation des catégories ===\n",
      "\n",
      "Catégories avant harmonisation:\n",
      "Catégorie\n",
      "Épicerie              9\n",
      "Laitage               8\n",
      "epicerie              6\n",
      "Fruits & Légumes      4\n",
      "Boissons              3\n",
      "nan                   2\n",
      "Boulangerie           2\n",
      "épicerie              1\n",
      "fruits et legumes     1\n",
      "oeufs                 1\n",
      "laitage               1\n",
      "Boucherie             1\n",
      "Poissonnerie          1\n",
      "fruits-legumes        1\n",
      "Œufs & Ovoproduits    1\n",
      "Fruits/Légumes        1\n",
      "boisson               1\n",
      "boissons              1\n",
      "Crèmerie              1\n",
      "Cremerie              1\n",
      "Charcuterie           1\n",
      "charcuterie           1\n",
      "Divers                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Catégories après harmonisation:\n",
      "Catégorie\n",
      "épicerie              16\n",
      "laitage                9\n",
      "fruits & légumes       5\n",
      "boissons               5\n",
      "œufs & ovoproduits     2\n",
      "boulangerie            2\n",
      "crèmerie               2\n",
      "charcuterie            2\n",
      "nan                    2\n",
      "fruits et legumes      1\n",
      "fruits/légumes         1\n",
      "poissonnerie           1\n",
      "boucherie              1\n",
      "divers                 1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Harmonisation des catégories ===\")\n",
    "print(f\"\\nCatégories avant harmonisation:\")\n",
    "print(df['Catégorie'].value_counts())\n",
    "\n",
    "# Standardise categories\n",
    "df['Catégorie'] = df['Catégorie'].str.lower().str.strip()\n",
    "\n",
    "# Category mapping\n",
    "mapping_categories = {\n",
    "    'epicerie': 'épicerie',\n",
    "    'boisson': 'boissons',\n",
    "    'fruits-legumes': 'fruits & légumes',\n",
    "    'fruits/legumes': 'fruits & légumes',\n",
    "    'fruits-legumes': 'fruits & légumes',\n",
    "    'laitage': 'laitage',\n",
    "    'cremerie': 'crèmerie',\n",
    "    'oeufs': 'œufs & ovoproduits',\n",
    "    'boissons': 'boissons',\n",
    "    'épicerie': 'épicerie'\n",
    "}\n",
    "\n",
    "df['Catégorie'] = df['Catégorie'].replace(mapping_categories)\n",
    "\n",
    "print(f\"\\nCatégories après harmonisation:\")\n",
    "print(df['Catégorie'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Unification du format des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unification des dates ===\n",
      "\n",
      "Exemples de dates avant conversion:\n",
      "0     2025-09-01\n",
      "1     01/09/2025\n",
      "2     2025/09/01\n",
      "3     2025-09-02\n",
      "4     02-09-2025\n",
      "5     2025-09-02\n",
      "6       02/09/25\n",
      "7     2025-09-03\n",
      "8     2025-09-03\n",
      "9     2025-09-03\n",
      "10    03/09/2025\n",
      "11    2025-09-04\n",
      "12    04-09-2025\n",
      "13    2025-09-04\n",
      "14    2025-09-04\n",
      "15    2025-09-05\n",
      "16    05/09/2025\n",
      "17    2025/09/05\n",
      "18    2025-09-05\n",
      "19    2025-09-06\n",
      "Name: Date, dtype: object\n",
      "Type de la colonne Date: object\n",
      "\n",
      "--- Conversion des dates en cours ---\n",
      "\n",
      "Exemples de dates après conversion:\n",
      "0    2025-09-01\n",
      "1    2025-09-01\n",
      "2    2025-09-01\n",
      "3    2025-09-02\n",
      "4    2025-09-02\n",
      "5    2025-09-02\n",
      "6    2025-09-02\n",
      "7    2025-09-03\n",
      "8    2025-09-03\n",
      "9    2025-09-03\n",
      "10   2025-09-03\n",
      "11   2025-09-04\n",
      "12   2025-09-04\n",
      "13   2025-09-04\n",
      "14   2025-09-04\n",
      "15   2025-09-05\n",
      "16   2025-09-05\n",
      "17   2025-09-05\n",
      "18   2025-09-05\n",
      "19   2025-09-06\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "Type de la colonne Date: datetime64[ns]\n",
      "\n",
      "Nombre de dates invalides: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Unification des dates ===\")\n",
    "print(f\"\\nExemples de dates avant conversion:\")\n",
    "print(df['Date'].head(20))\n",
    "print(f\"Type de la colonne Date: {df['Date'].dtype}\")\n",
    "\n",
    "# Function to parse dates with multiple formats\n",
    "def parse_mixed_dates(date_str):\n",
    "    \"\"\"\n",
    "    Parse dates with mixed formats:\n",
    "    - YYYY-MM-DD, YYYY/MM/DD (year first)\n",
    "    - DD/MM/YYYY, DD-MM-YYYY, DD/MM/YY (day first)\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    \n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    # First try year-first format (YYYY-MM-DD or YYYY/MM/DD)\n",
    "    # If it starts with 4 digits, it's probably YYYY\n",
    "    if len(date_str) >= 10 and date_str[:4].isdigit():\n",
    "        try:\n",
    "            return pd.to_datetime(date_str)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Otherwise try day-first format (DD/MM/YYYY, DD-MM-YYYY, DD/MM/YY)\n",
    "    return pd.to_datetime(date_str, dayfirst=True, errors='coerce')\n",
    "\n",
    "# Apply the parsing function\n",
    "print(\"\\n--- Conversion des dates en cours ---\")\n",
    "df['Date'] = df['Date'].apply(parse_mixed_dates)\n",
    "\n",
    "print(f\"\\nExemples de dates après conversion:\")\n",
    "print(df['Date'].head(20))\n",
    "print(f\"Type de la colonne Date: {df['Date'].dtype}\")\n",
    "\n",
    "# Check for unconverted dates (NaT)\n",
    "invalid_dates = df['Date'].isna().sum()\n",
    "print(f\"\\nNombre de dates invalides: {invalid_dates}\")\n",
    "\n",
    "if invalid_dates > 0:\n",
    "    print(\"\\nDates qui n'ont pas pu être converties:\")\n",
    "    print(df[df['Date'].isna()][['TransactionID', 'Produit', 'Date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gestion des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gestion des valeurs manquantes ==="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valeurs manquantes avant traitement:\n",
      "Quantité    2\n",
      "Prix        2\n",
      "dtype: int64\n",
      "\n",
      "Statistiques Quantité avant imputation:\n",
      "count      48.000000\n",
      "mean       23.520833\n",
      "std       143.966159\n",
      "min        -1.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         4.250000\n",
      "max      1000.000000\n",
      "Name: Quantité, dtype: float64\n",
      "\n",
      "Statistiques Prix avant imputation:\n",
      "count     48.000000\n",
      "mean      22.756458\n",
      "std      143.916366\n",
      "min        0.000000\n",
      "25%        0.897500\n",
      "50%        1.575000\n",
      "75%        2.825000\n",
      "max      999.000000\n",
      "Name: Prix, dtype: float64\n",
      "\n",
      "Valeur médiane pour Quantité: 2.0\n",
      "Valeur médiane pour Prix: 1.575\n",
      "\n",
      "Nombre de valeurs imputées:\n",
      "  - Quantité: 2\n",
      "  - Prix: 2\n",
      "\n",
      "Valeurs manquantes après traitement:\n",
      "Quantité    0\n",
      "Prix        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zahor\\AppData\\Local\\Temp\\ipykernel_25488\\2178208705.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Quantité'].fillna(median_quantity, inplace=True)\n",
      "C:\\Users\\zahor\\AppData\\Local\\Temp\\ipykernel_25488\\2178208705.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Prix'].fillna(median_price, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Gestion des valeurs manquantes ===\")\n",
    "print(f\"\\nValeurs manquantes avant traitement:\")\n",
    "print(df[['Quantité', 'Prix']].isnull().sum())\n",
    "\n",
    "# Statistics before imputation\n",
    "print(f\"\\nStatistiques Quantité avant imputation:\")\n",
    "print(df['Quantité'].describe())\n",
    "print(f\"\\nStatistiques Prix avant imputation:\")\n",
    "print(df['Prix'].describe())\n",
    "\n",
    "# Impute missing values (median)\n",
    "median_quantity = df['Quantité'].median()\n",
    "median_price = df['Prix'].median()\n",
    "\n",
    "print(f\"\\nValeur médiane pour Quantité: {median_quantity}\")\n",
    "print(f\"Valeur médiane pour Prix: {median_price}\")\n",
    "\n",
    "# Fill empties\n",
    "nb_missing_quantity = df['Quantité'].isnull().sum()\n",
    "nb_missing_price = df['Prix'].isnull().sum()\n",
    "\n",
    "df['Quantité'].fillna(median_quantity, inplace=True)\n",
    "df['Prix'].fillna(median_price, inplace=True)\n",
    "\n",
    "print(f\"\\nNombre de valeurs imputées:\")\n",
    "print(f\"  - Quantité: {nb_missing_quantity}\")\n",
    "print(f\"  - Prix: {nb_missing_price}\")\n",
    "\n",
    "print(f\"\\nValeurs manquantes après traitement:\")\n",
    "print(df[['Quantité', 'Prix']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Détection et traitement des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Détection des valeurs aberrantes ===\n",
      "\n",
      "Quantités négatives: 1\n",
      "    TransactionID Produit  Quantité\n",
      "31             32    lait      -1.0\n",
      "\n",
      "Quantités excessives (>100): 1\n",
      "    TransactionID Produit  Quantité\n",
      "32             33    pain    1000.0\n",
      "\n",
      "Prix aberrants (>100): 1\n",
      "    TransactionID Produit   Prix\n",
      "33             34   pâtes  999.0\n",
      "\n",
      "Produits vides ou '—': 2\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Détection des valeurs aberrantes ===\")\n",
    "\n",
    "# Negative quantity\n",
    "negative_quantity = (df['Quantité'] < 0).sum()\n",
    "print(f\"\\nQuantités négatives: {negative_quantity}\")\n",
    "if negative_quantity > 0:\n",
    "    print(df[df['Quantité'] < 0][['TransactionID', 'Produit', 'Quantité']])\n",
    "\n",
    "# Quantity > 100\n",
    "excessive_quantity = (df['Quantité'] > 100).sum()\n",
    "print(f\"\\nQuantités excessives (>100): {excessive_quantity}\")\n",
    "if excessive_quantity > 0:\n",
    "    print(df[df['Quantité'] > 100][['TransactionID', 'Produit', 'Quantité']])\n",
    "\n",
    "# Outlier prices (> 100)\n",
    "outlier_prices = (df['Prix'] > 100).sum()\n",
    "print(f\"\\nPrix aberrants (>100): {outlier_prices}\")\n",
    "if outlier_prices > 0:\n",
    "    print(df[df['Prix'] > 100][['TransactionID', 'Produit', 'Prix']])\n",
    "\n",
    "# Empty products\n",
    "empty_products = (df['Produit'] == '—').sum() + (df['Produit'] == '').sum()\n",
    "print(f\"\\nProduits vides ou '—': {empty_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Traitement des valeurs aberrantes ===\n",
      "\n",
      "Nombre de lignes supprimées (produits invalides): 2\n",
      "Nombre total de lignes restantes: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zahor\\AppData\\Local\\Temp\\ipykernel_25488\\2581040013.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Quantité'].fillna(median_quantity, inplace=True)\n",
      "C:\\Users\\zahor\\AppData\\Local\\Temp\\ipykernel_25488\\2581040013.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Prix'].fillna(median_price, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Traitement des valeurs aberrantes ===\")\n",
    "len_before_cleaning = len(df)\n",
    "\n",
    "# Negative quantity: convert into NaN, then fill with median\n",
    "df.loc[df['Quantité'] < 0, 'Quantité'] = pd.NA\n",
    "nb_corrected_neg_quantity = df['Quantité'].isna().sum()\n",
    "\n",
    "# Excessive quantity: convert into NaN, then fill with median\n",
    "df.loc[df['Quantité'] > 100, 'Quantité'] = pd.NA\n",
    "nb_corrected_exc_quantity = df['Quantité'].isna().sum() - nb_corrected_neg_quantity\n",
    "\n",
    "# Impute outlier quantities\n",
    "df['Quantité'].fillna(median_quantity, inplace=True)\n",
    "\n",
    "# Outlier prices\n",
    "df.loc[df['Prix'] > 100, 'Prix'] = pd.NA\n",
    "nb_corrected_price_outlier = df['Prix'].isna().sum()\n",
    "\n",
    "# Impute outlier prices\n",
    "df['Prix'].fillna(median_price, inplace=True)\n",
    "\n",
    "# Delete empties\n",
    "df = df[df['Produit'] != '—']\n",
    "df = df[df['Produit'] != '']\n",
    "df = df[df['Produit'] != 'nan']\n",
    "\n",
    "len_after_cleaning = len(df)\n",
    "nb_deleted = len_before_cleaning - len_after_cleaning\n",
    "\n",
    "print(f\"\\nNombre de lignes supprimées (produits invalides): {nb_deleted}\")\n",
    "print(f\"Nombre total de lignes restantes: {len_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Suppression de la colonne 'Notes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Suppression de la colonne Notes ===\n",
      "\n",
      "Colonnes avant suppression: ['TransactionID', 'Produit', 'Quantité', 'Prix', 'Catégorie', 'Date', 'Notes', 'Produit_normalise']\n",
      "Colonnes après suppression: ['TransactionID', 'Produit', 'Quantité', 'Prix', 'Catégorie', 'Date']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Suppression de la colonne Notes ===\")\n",
    "print(f\"\\nColonnes avant suppression: {df.columns.tolist()}\")\n",
    "\n",
    "# Delete columns\n",
    "if 'Produit_normalise' in df.columns:\n",
    "    df = df.drop(columns=['Produit_normalise'])\n",
    "\n",
    "if 'Notes' in df.columns:\n",
    "    df = df.drop(columns=['Notes'])\n",
    "\n",
    "print(f\"Colonnes après suppression: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Vérification finale et export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vérification finale ===\n",
      "\n",
      "Dimensions du dataset final: (48, 6)\n",
      "\n",
      "Aperçu du dataset nettoyé:\n",
      "   TransactionID Produit  Quantité  Prix          Catégorie       Date\n",
      "0              1    pain       1.0  1.20        boulangerie 2025-09-01\n",
      "1              2    lait       2.0  0.95            laitage 2025-09-01\n",
      "2              3  beurre       1.0  2.80            laitage 2025-09-01\n",
      "3              4  tomate       3.0  1.99   fruits & légumes 2025-09-02\n",
      "4              5  tomate       2.0  2.10  fruits et legumes 2025-09-02\n",
      "5              6   pâtes       1.0  0.89           épicerie 2025-09-02\n",
      "6              7   pâtes       2.0  0.89           épicerie 2025-09-02\n",
      "7              8     riz       1.0  1.10           épicerie 2025-09-03\n",
      "8              9     riz       5.0  1.10           épicerie 2025-09-03\n",
      "9             10  yaourt       6.0  0.45            laitage 2025-09-03\n",
      "\n",
      "=== Informations finales ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48 entries, 0 to 50\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   TransactionID  48 non-null     int64         \n",
      " 1   Produit        48 non-null     object        \n",
      " 2   Quantité       48 non-null     float64       \n",
      " 3   Prix           48 non-null     float64       \n",
      " 4   Catégorie      48 non-null     object        \n",
      " 5   Date           48 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(2)\n",
      "memory usage: 2.6+ KB\n",
      "\n",
      "=== Valeurs manquantes finales ===\n",
      "TransactionID    0\n",
      "Produit          0\n",
      "Quantité         0\n",
      "Prix             0\n",
      "Catégorie        0\n",
      "Date             0\n",
      "dtype: int64\n",
      "\n",
      "=== Statistiques finales ===\n",
      "       TransactionID   Quantité       Prix                 Date\n",
      "count      48.000000  48.000000  48.000000                   48\n",
      "mean       24.625000   2.812500   2.009583  2025-09-05 21:30:00\n",
      "min         1.000000   1.000000   0.280000  2025-09-01 00:00:00\n",
      "25%        12.750000   1.000000   0.937500  2025-09-03 00:00:00\n",
      "50%        24.500000   2.000000   1.575000  2025-09-06 00:00:00\n",
      "75%        36.250000   3.250000   2.800000  2025-09-08 00:00:00\n",
      "max        50.000000  12.000000   7.500000  2025-09-12 00:00:00\n",
      "std        14.203124   2.606508   1.646926                  NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Vérification finale ===\")\n",
    "print(f\"\\nDimensions du dataset final: {df.shape}\")\n",
    "print(f\"\\nAperçu du dataset nettoyé:\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(f\"\\n=== Informations finales ===\")\n",
    "df.info()\n",
    "\n",
    "print(f\"\\n=== Valeurs manquantes finales ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\n=== Statistiques finales ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fichier 'donnees_achats_propre.xlsx' exporté avec succès!\n",
      "Fichier 'donnees_achats_propre.csv' exporté avec succès!\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned df\n",
    "df.to_excel('donnees_achats_propre.xlsx', index=False)\n",
    "print(\"\\nFichier 'donnees_achats_propre.xlsx' exporté avec succès!\")\n",
    "\n",
    "# Export in csv\n",
    "df.to_csv('donnees_achats_propre.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Fichier 'donnees_achats_propre.csv' exporté avec succès!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
